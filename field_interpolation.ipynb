{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "018dfe97",
   "metadata": {},
   "source": [
    "Field Interpolation\n",
    "==============\n",
    "\n",
    "Given a set of samples of an unkown function, _estimate_ a function $f$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88aa7341",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set_theme()\n",
    "sns.set(style='darkgrid', context='talk', palette='Pastel1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff6ad0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = [12, 5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc62dd0",
   "metadata": {},
   "source": [
    "$$f(0) = -1$$\n",
    "$$f(1) = 0.2$$\n",
    "$$f(2) = 0.9$$\n",
    "$$f(3) = 2.1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bbc81ff",
   "metadata": {},
   "source": [
    "Estimate a line, $f(x) = kx + m$, using linear last squares\n",
    "\n",
    "$$-1 = k*0 + m$$\n",
    "$$0.2 = k*1 + m$$\n",
    "$$0.9 = k*2 + m$$\n",
    "$$2.1 = k*3 + m$$\n",
    "\n",
    "Or just\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "0 & 1 \\\\\n",
    "1 & 1 \\\\\n",
    "2 & 1 \\\\\n",
    "3 & 1 \\\\\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix} k \\\\ m \\end{bmatrix}\n",
    "= \n",
    "\\begin{bmatrix}\n",
    "-1 \\\\ 0.2 \\\\ 0.9 \\\\ 2.1 \\\\\n",
    "\\end{bmatrix}$$\n",
    "$$A\\begin{bmatrix} k \\\\ m \\end{bmatrix} = \\bf{b}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59e689b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# sampled points\n",
    "x = np.array([0, 1, 2, 3])\n",
    "y = np.array([-1, 0.2, 0.9, 2.1])\n",
    "\n",
    "A = np.vstack([x, np.ones(x.shape)]).T\n",
    "k, m = np.linalg.lstsq(A, y, rcond=None)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a490587",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(x0, y0, x1, y1):\n",
    "    plt.plot(x0, y0, 'o', label='Original data')\n",
    "    plt.plot(x1, y1, label='Fitted model')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "plot(x, y, x, k*x + m)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54158e64",
   "metadata": {},
   "source": [
    "### Lattice model\n",
    "Instead of using a line, lets use the _values_ at specific lattice points as the model. We use a finite grid with a high and low limit. The downside is we can only evaluate it within the bounds, whereas the line model could be evaluated everywhere.\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "1 & 0 & 0 & 0 \\\\\n",
    "0 & 1 & 0 & 0 \\\\\n",
    "0 & 0 & 1 & 0 \\\\\n",
    "0 & 0 & 0 & 1 \\\\\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "x_0 \\\\ x_1 \\\\ x_2 \\\\ x_3\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "-1 \\\\ 0.2 \\\\ 0.9 \\\\ 2.1 \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$A\\bf{x} = \\bf{b}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11143d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(x, y, x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7754c1",
   "metadata": {},
   "source": [
    "But what if we have more points? And that are not exactly _on_ the lattice grid?\n",
    "\n",
    "$$f(0) = -1$$\n",
    "$$f(1) = 0.2$$\n",
    "$$f(2) = 0.9$$\n",
    "$$f(2.2) = 1$$\n",
    "$$f(3) = 2.1$$\n",
    "\n",
    "Then we do linear interpolation (\"lerp\"). The closest lattice points are 2 and 3.\n",
    "\n",
    "$$0.8 \\cdot f(2) + 0.2 \\cdot f(3) = 1$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b14a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPSILON = 1e-8\n",
    "\n",
    "def value_constraints(xx, n):\n",
    "    for f, i in zip(*np.modf(xx)):\n",
    "        row = np.zeros(n)\n",
    "        if 1 - f > EPSILON:\n",
    "            row[int(i)] = 1 - f\n",
    "        if f > EPSILON:\n",
    "            row[int(i) + 1] = f\n",
    "        yield row\n",
    "    \n",
    "x = np.array([0, 1, 2, 2.2, 3])\n",
    "y = np.array([-1, 0.2, 0.9, 1, 2.1])\n",
    "\n",
    "A = np.array(list(value_constraints(x, 4)))\n",
    "print(f\"solving {A.shape[0]} equations for {A.shape[1]} unkowns\")\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7123b0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "xg = np.linalg.lstsq(A, y, rcond=None)[0]\n",
    "plot(x, y, np.arange(len(xg)), xg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e12344",
   "metadata": {},
   "source": [
    "## Smoothess constraints\n",
    "We can also coerce the grid model to be more smooth by $f''(x) = 0$. If we aproximate $f''$ by the finite difference $f''(x) = f(⌊x⌋ + 1) - f(⌊x⌋)$ (and likewise for $f'$) we can formulate it like so\n",
    "\n",
    "$$f(n + 1) - f(n) = f(n + 2) - f(n)$$\n",
    "\n",
    "For our 4-element grid we get\n",
    "$$f(1) - f(0) = f(2) - f(1)$$\n",
    "$$f(2) - f(1) = f(3) - f(2)$$\n",
    "\n",
    "Or in matrix form\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "1 & -2 & 1 & 0 \\\\\n",
    "0 & 1 & -2 & 1 \\\\\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "x_0 \\\\ x_1 \\\\ x_2 \\\\ x_3\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "0 \\\\ 0 \\\\\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8501c05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smoothness_constraints(n):\n",
    "    for i in range(n - 2):\n",
    "        row = np.zeros(n)\n",
    "        row[i + 0] = 1\n",
    "        row[i + 1] = -2\n",
    "        row[i + 2] = 1\n",
    "        yield row\n",
    "\n",
    "A = np.array(list(value_constraints(x, 4)) + list(smoothness_constraints(4)))\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93f20a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "xg = np.linalg.lstsq(A, np.hstack([y, np.zeros(4 - 2)]), rcond=None)[0]\n",
    "plot(x, y, np.arange(len(xg)), xg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a12efa2",
   "metadata": {},
   "source": [
    "## Gradient constraints\n",
    "We can also add gradient constraints if these are known. Intead of linear interpolation, just nearest neighgbor can be used. Let's say we know $f'(1.3) = 2$, we can add it as just $f(2) - f(1) = 2$\n",
    "\n",
    "\n",
    "Or in matrix form\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "0 & -1 & 1 & 0 \\\\\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "x_0 \\\\ x_1 \\\\ x_2 \\\\ x_3\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "2 \\\\\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44f5527",
   "metadata": {},
   "source": [
    "## From another dimension\n",
    "This is easy to extend with more dimenensions. For example in 2D $\\nabla f(2.1, 5.8) = \\begin{bmatrix} -1 & 3 \\end{bmatrix}^T$ just becomes\n",
    "\n",
    "$$f(3, 6) - f(2, 6) = -1$$\n",
    "$$f(2, 6) - f(2, 5) =  3$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7af5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "def from_complex(ca: List[complex]) -> np.ndarray:\n",
    "    \"\"\"convert to 2d cordinates from complex\"\"\"\n",
    "    return np.vstack([ca.real, ca.imag]).T\n",
    "\n",
    "from mini_svg.load import load_svg\n",
    "shape = load_svg('volumental.svg')\n",
    "\n",
    "np.random.seed(17)\n",
    "ts = np.random.random(256)\n",
    "sampled_points = from_complex(np.array([shape.point(t) for t in ts]))\n",
    "\n",
    "plt.plot(sampled_points[:, 0], sampled_points[:, 1], '.', label='volumental.svg')\n",
    "plt.ylim(max(plt.ylim()), min(plt.ylim()))\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db1ae66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(a, axis=-1, order=2):\n",
    "    \"\"\"Normalizes array to have length 1 along specificed axis.\"\"\"\n",
    "    norms = np.linalg.norm(a, order, axis)\n",
    "    return a / np.expand_dims(norms, axis)\n",
    "\n",
    "sampled_normals = normalize(from_complex(np.array([shape.tangent(t) for t in ts]) * -1j))\n",
    "\n",
    "plt.quiver(\n",
    "    sampled_points[:, 0], sampled_points[:, 1],\n",
    "    sampled_normals[:, 0], sampled_normals[:, 1],\n",
    "    width=0.001)\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f052e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "resolution = (14, 24)\n",
    "\n",
    "def fit_to(a, resolution, padding_fraction=0):\n",
    "    \"\"\"Rescales cordinates to fit a specific resolution with paddning\"\"\"\n",
    "    r = np.flip(np.array(resolution)) - np.array([1, 1])\n",
    "    top_left = np.min(a, axis=0)\n",
    "    bottom_right = np.max(a, axis=0)\n",
    "    size = bottom_right - top_left\n",
    "    scale = np.min(r / size)\n",
    "    normalized = scale * (a - top_left)\n",
    "    padding = r * padding_fraction\n",
    "    return (normalized + 0.5 * padding) * (1 - padding_fraction)\n",
    "\n",
    "points = fit_to(sampled_points, resolution, 0.1)\n",
    "normals = sampled_normals  # normals are invariant to scaling and translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3cb97fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def index(x: int, y: int, resolution):\n",
    "    \"\"\"Returns the index into the grid vector\"\"\"\n",
    "    _, w = resolution\n",
    "    return int(x) + int(y) * w\n",
    "\n",
    "def value_constraints_2d(points, values, resolution):\n",
    "    \"\"\"\"binlinear interpolation\"\"\"\n",
    "    rows = []\n",
    "    n = np.prod(np.array(resolution))\n",
    "    for (fx, fy), (ix, iy), value in zip(*np.modf(points), values):\n",
    "        row = np.zeros(n)\n",
    "        row[index(ix, iy, resolution)] = (1 - fx) * (1 - fy)\n",
    "        row[index(ix + 1, iy, resolution)] = fx * (1 - fy)\n",
    "        row[index(ix, iy + 1, resolution)] = (1 - fx) * fy\n",
    "        row[index(ix + 1, iy + 1, resolution)] = fx * fy\n",
    "        rows.append(row)\n",
    "    \n",
    "    return np.vstack(rows), values\n",
    "\n",
    "def gradient_constraints_2d(points, normals, resolution):\n",
    "    rows = []\n",
    "    values = []\n",
    "    n = np.prod(np.array(resolution))\n",
    "    #∇f(x, y) = (nx, ny)\n",
    "    # nearest neighbor\n",
    "    #f(⌊⌊x⌋ + 1, ⌊y⌋ + 1) - f(⌊x⌋, ⌊y⌋ + 1) = nx\n",
    "    #f(⌊⌊x⌋, ⌊y⌋ + 1) - f(⌊x⌋, ⌊y⌋) = ny\n",
    "    for (fx, fy), (ix, iy), (nx, ny) in zip(*np.modf(points), normals): \n",
    "        del fx, fy  # ignore fraction part\n",
    "\n",
    "        row = np.zeros(n)\n",
    "        row[index(ix + 1, iy + 1, resolution)] = 1\n",
    "        row[index(ix, iy + 1, resolution)] = -1\n",
    "        rows.append(row)\n",
    "        values.append(nx)\n",
    "        \n",
    "        row = np.zeros(n)\n",
    "        row[index(ix, iy + 1, resolution)] = 1\n",
    "        row[index(ix, iy, resolution)] = -1\n",
    "        rows.append(row)\n",
    "        values.append(ny)\n",
    "\n",
    "    return np.array(rows), np.array(values)\n",
    "\n",
    "def smoothness_constraints_2d(resolution):\n",
    "    rows = []\n",
    "    values = []\n",
    "    n = np.prod(np.array(resolution))\n",
    "    h, w = resolution\n",
    "    for iy, ix in np.ndindex(h - 2, w - 2):\n",
    "        row = np.zeros(n)\n",
    "        row[index(ix + 0, iy, resolution)] = 1\n",
    "        row[index(ix + 1, iy, resolution)] = -2\n",
    "        row[index(ix + 2, iy, resolution)] = 1\n",
    "        rows.append(row)\n",
    "        values.append(0)\n",
    "        \n",
    "        row = np.zeros(n)\n",
    "        row[index(ix, iy + 0, resolution)] = 1\n",
    "        row[index(ix, iy + 1, resolution)] = -2\n",
    "        row[index(ix, iy + 2, resolution)] = 1\n",
    "        rows.append(row)\n",
    "        values.append(0)\n",
    "        \n",
    "    return np.array(rows), np.array(values)\n",
    "\n",
    "def field_interpolation(resolution, points, normals):\n",
    "    rows0, values0 = value_constraints_2d(points, np.zeros(len(points)), resolution)\n",
    "    rows1, values1 = gradient_constraints_2d(points, normals, resolution)\n",
    "    rows2, values2 = smoothness_constraints_2d(resolution)\n",
    "    A = np.vstack([rows0, rows1, rows2])\n",
    "    b = np.concatenate([values0, values1, values2])\n",
    "    print(f\"solving {A.shape[0]} equations for {A.shape[1]} unkowns\")\n",
    "    sdf = np.linalg.lstsq(A, b, rcond=None)[0]\n",
    "    return sdf.reshape(resolution)\n",
    "\n",
    "\n",
    "# compute signed distance function (sdf)\n",
    "sdf = field_interpolation(resolution, points, normals)\n",
    "\n",
    "# show sdf\n",
    "plt.imshow(sdf)\n",
    "plt.colorbar()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794ca13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot reconstructed surface\n",
    "plt.contour(sdf, levels=[0])\n",
    "plt.axis('equal')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ec857c",
   "metadata": {},
   "source": [
    "## Noise\n",
    "Let's add ~make~ add some noise!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500d7378",
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_points = points + np.random.normal(scale=0.5, size=points.shape)\n",
    "\n",
    "plt.plot(noisy_points[:, 0], noisy_points[:, 1], '.', label='noisy points')\n",
    "plt.ylim(max(plt.ylim()), min(plt.ylim()))\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97784bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf = field_interpolation(resolution, noisy_points, normals)\n",
    "\n",
    "plt.imshow(sdf)\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "# plot reconstructed surface\n",
    "plt.contour(sdf, levels=[0])\n",
    "plt.axis('equal')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e148ec",
   "metadata": {},
   "source": [
    "## Weights\n",
    "We can easily weight the different constraints by just multiplying each row by a weight."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
